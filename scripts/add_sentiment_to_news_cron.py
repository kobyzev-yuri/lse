#!/usr/bin/env python3
"""
Cron —Å–∫—Ä–∏–ø—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è sentiment –∞–Ω–∞–ª–∏–∑–∞ –∫ –Ω–æ–≤–æ—Å—Ç—è–º –±–µ–∑ sentiment
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ sentiment –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ RSS –∏ NewsAPI
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import logging
import os
from datetime import datetime, timedelta
from sqlalchemy import create_engine, text
import pandas as pd

from config_loader import get_database_url, get_config_value
from services.sentiment_analyzer import calculate_sentiment

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/add_sentiment_to_news.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


def add_sentiment_to_news(
    days_back: int = 1,
    limit: int = None,
    batch_size: int = 10,
    min_content_length: int = 20
):
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç sentiment –∞–Ω–∞–ª–∏–∑ –∫ –Ω–æ–≤–æ—Å—Ç—è–º –±–µ–∑ sentiment
    
    Args:
        days_back: –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
        limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–µ—Å–ª–∏ None - –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ)
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (LLM –∑–∞–ø—Ä–æ—Å—ã)
        min_content_length: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    """
    logger.info("=" * 60)
    logger.info("üîÑ –ù–∞—á–∞–ª–æ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è sentiment –∞–Ω–∞–ª–∏–∑–∞ –∫ –Ω–æ–≤–æ—Å—Ç—è–º")
    logger.info("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ LLM
    use_llm = get_config_value('USE_LLM', 'false').lower() == 'true'
    if not use_llm:
        logger.warning("‚ö†Ô∏è USE_LLM=false, sentiment –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return
    
    db_url = get_database_url()
    engine = create_engine(db_url)
    
    analyzed_count = 0
    updated_count = 0
    skipped_count = 0
    error_count = 0
    
    try:
        # –ù–∞—Ö–æ–¥–∏–º –Ω–æ–≤–æ—Å—Ç–∏ –±–µ–∑ sentiment –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π
        cutoff_date = datetime.now() - timedelta(days=days_back)
        
        with engine.connect() as conn:
            query = text("""
                SELECT id, ticker, content, source, event_type
                FROM knowledge_base
                WHERE ts >= :cutoff_date
                  AND sentiment_score IS NULL
                  AND content IS NOT NULL
                  AND LENGTH(content) >= :min_length
                  AND source IN ('RSS', 'NEWSAPI', 'MANUAL')
                ORDER BY ts DESC
                LIMIT :limit
            """)
            
            params = {
                "cutoff_date": cutoff_date,
                "min_length": min_content_length,
                "limit": limit if limit else 1000
            }
            
            news_df = pd.read_sql(query, conn, params=params)
            
            if news_df.empty:
                logger.info("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –±–µ–∑ sentiment –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
                return
            
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(news_df)} –Ω–æ–≤–æ—Å—Ç–µ–π –±–µ–∑ sentiment –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏ (LLM –∑–∞–ø—Ä–æ—Å—ã –º–æ–≥—É—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º–∏)
            for i in range(0, len(news_df), batch_size):
                batch = news_df.iloc[i:i+batch_size]
                
                for _, row in batch.iterrows():
                    try:
                        news_id = int(row['id'])
                        content = str(row['content'])
                        ticker = row.get('ticker', 'UNKNOWN')
                        
                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º sentiment —á–µ—Ä–µ–∑ LLM
                        sentiment_score, insight = calculate_sentiment(content)
                        
                        if sentiment_score is not None:
                            # –û–±–Ω–æ–≤–ª—è–µ–º sentiment_score –≤ –ë–î
                            with engine.begin() as conn:
                                update_query = text("""
                                    UPDATE knowledge_base
                                    SET sentiment_score = :sentiment_score
                                    WHERE id = :news_id
                                """)
                                conn.execute(
                                    update_query,
                                    {
                                        "news_id": news_id,
                                        "sentiment_score": sentiment_score
                                    }
                                )
                            
                            updated_count += 1
                            logger.debug(
                                f"‚úÖ –ù–æ–≤–æ—Å—Ç—å ID={news_id} ({ticker}): "
                                f"sentiment={sentiment_score:.3f}"
                            )
                            
                            if insight:
                                logger.debug(f"   Insight: {insight[:100]}...")
                        else:
                            skipped_count += 1
                        
                        analyzed_count += 1
                        
                        # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∫ LLM
                        import time
                        time.sleep(0.5)
                        
                    except Exception as e:
                        error_count += 1
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–∏ ID={row['id']}: {e}")
                
                logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {min(i+batch_size, len(news_df))}/{len(news_df)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è sentiment: {e}", exc_info=True)
    
    logger.info("=" * 60)
    logger.info(
        f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ sentiment –∑–∞–≤–µ—Ä—à–µ–Ω–æ: "
        f"–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {analyzed_count}, "
        f"–æ–±–Ω–æ–≤–ª–µ–Ω–æ {updated_count}, "
        f"–ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped_count}, "
        f"–æ—à–∏–±–æ–∫ {error_count}"
    )
    logger.info("=" * 60)


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    days_back = int(os.getenv('SENTIMENT_DAYS_BACK', '1'))  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç–æ–ª—å–∫–æ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
    limit = None
    if os.getenv('SENTIMENT_LIMIT'):
        try:
            limit = int(os.getenv('SENTIMENT_LIMIT'))
        except ValueError:
            logger.warning(f"‚ö†Ô∏è –ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ SENTIMENT_LIMIT: {os.getenv('SENTIMENT_LIMIT')}")
    
    batch_size = int(os.getenv('SENTIMENT_BATCH_SIZE', '10'))  # –ú–µ–Ω—å—à–µ –±–∞—Ç—á –¥–ª—è LLM
    min_content_length = int(os.getenv('SENTIMENT_MIN_CONTENT_LENGTH', '20'))
    
    add_sentiment_to_news(
        days_back=days_back,
        limit=limit,
        batch_size=batch_size,
        min_content_length=min_content_length
    )


if __name__ == "__main__":
    main()
