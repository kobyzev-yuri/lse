"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–ª–∏—è–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ö–æ–¥—ã —Å–æ–±—ã—Ç–∏–π: –∫–∞–∫ —Ä—ã–Ω–æ–∫ –æ—Ç—Ä–µ–∞–≥–∏—Ä–æ–≤–∞–ª –Ω–∞ –Ω–æ–≤–æ—Å—Ç–∏ –≤ –ø—Ä–æ—à–ª–æ–º
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import logging
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta
import pandas as pd
from sqlalchemy import create_engine, text
import numpy as np

from config_loader import get_database_url

logger = logging.getLogger(__name__)


class NewsImpactAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ö–æ–¥—ã –Ω–æ–≤–æ—Å—Ç–µ–π/—Å–æ–±—ã—Ç–∏–π: –∫–∞–∫ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å —Ü–µ–Ω–∞ –ø–æ—Å–ª–µ —Å–æ–±—ã—Ç–∏—è
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è NewsImpactAnalyzer"""
        self.db_url = get_database_url()
        self.engine = create_engine(self.db_url)
        logger.info("‚úÖ NewsImpactAnalyzer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def analyze_event_outcome(
        self,
        event_id: int,
        ticker: str,
        days_after: int = 7,
        event_ts: Optional[datetime] = None
    ) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ö–æ–¥ —Å–æ–±—ã—Ç–∏—è: –∫–∞–∫ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å —Ü–µ–Ω–∞ –ø–æ—Å–ª–µ –Ω–æ–≤–æ—Å—Ç–∏
        
        Args:
            event_id: ID —Å–æ–±—ã—Ç–∏—è –∏–∑ trade_kb
            ticker: –¢–∏–∫–µ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
            days_after: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ—Å–ª–µ —Å–æ–±—ã—Ç–∏—è
            event_ts: –í—Ä–µ–º–µ–Ω–Ω–∞—è –º–µ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è (–µ—Å–ª–∏ None - –±–µ—Ä–µ—Ç—Å—è –∏–∑ –ë–î)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏—Å—Ö–æ–¥–∞:
            {
                'price_change_pct': float,      # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã —á–µ—Ä–µ–∑ N –¥–Ω–µ–π (%)
                'max_gain_pct': float,          # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç (%)
                'max_loss_pct': float,          # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ (%)
                'volatility_change': float,     # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                'sentiment_match': bool,        # –°–æ–≤–ø–∞–ª –ª–∏ sentiment —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º
                'outcome': str,                 # 'POSITIVE' | 'NEGATIVE' | 'NEUTRAL'
                'days_analyzed': int            # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–Ω–µ–π
            }
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –º–µ—Ç–∫—É —Å–æ–±—ã—Ç–∏—è
            if not event_ts:
                with self.engine.connect() as conn:
                    result = conn.execute(
                        text("SELECT ts FROM trade_kb WHERE id = :event_id"),
                        {"event_id": int(event_id)}  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ int –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                    )
                    row = result.fetchone()
                    if not row:
                        logger.warning(f"‚ö†Ô∏è –°–æ–±—ã—Ç–∏–µ ID={event_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                        return None
                    event_ts = row[0]
            
            # –ü–æ–ª—É—á–∞–µ–º —Ü–µ–Ω—É –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–æ–±—ã—Ç–∏—è (–±–ª–∏–∂–∞–π—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é)
            with self.engine.connect() as conn:
                # –ò—â–µ–º –∫–æ—Ç–∏—Ä–æ–≤–∫—É –Ω–∞ –¥–∞—Ç—É —Å–æ–±—ã—Ç–∏—è –∏–ª–∏ –±–ª–∏–∂–∞–π—à—É—é –ø–æ—Å–ª–µ
                price_query = text("""
                    SELECT date, close, volatility_5
                    FROM quotes
                    WHERE ticker = :ticker
                      AND date >= :event_date
                    ORDER BY date ASC
                    LIMIT 1
                """)
                price_result = conn.execute(
                    price_query,
                    {
                        "ticker": ticker,
                        "event_date": event_ts.date()
                    }
                )
                event_price_row = price_result.fetchone()
                
                if not event_price_row:
                    logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –∫–æ—Ç–∏—Ä–æ–≤–æ–∫ –¥–ª—è {ticker} –Ω–∞ –¥–∞—Ç—É —Å–æ–±—ã—Ç–∏—è {event_ts.date()}")
                    return None
                
                event_price = float(event_price_row[1])
                event_volatility = float(event_price_row[2]) if event_price_row[2] else None
                
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ—Ç–∏—Ä–æ–≤–∫–∏ –∑–∞ N –¥–Ω–µ–π –ø–æ—Å–ª–µ —Å–æ–±—ã—Ç–∏—è
                end_date = event_ts.date() + timedelta(days=days_after)
                quotes_query = text("""
                    SELECT date, close, volatility_5
                    FROM quotes
                    WHERE ticker = :ticker
                      AND date > :event_date
                      AND date <= :end_date
                    ORDER BY date ASC
                """)
                quotes_df = pd.read_sql(
                    quotes_query,
                    conn,
                    params={
                        "ticker": ticker,
                        "event_date": event_ts.date(),
                        "end_date": end_date
                    }
                )
            
            if quotes_df.empty:
                logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –∫–æ—Ç–∏—Ä–æ–≤–æ–∫ –¥–ª—è {ticker} –ø–æ—Å–ª–µ —Å–æ–±—ã—Ç–∏—è {event_ts.date()}")
                return None
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            final_price = float(quotes_df.iloc[-1]['close'])
            price_change_pct = ((final_price - event_price) / event_price) * 100
            
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç –∏ –ø–∞–¥–µ–Ω–∏–µ
            quotes_df['price_change_pct'] = ((quotes_df['close'] - event_price) / event_price) * 100
            max_gain_pct = float(quotes_df['price_change_pct'].max())
            max_loss_pct = float(quotes_df['price_change_pct'].min())
            
            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            volatility_change = None
            if event_volatility and not quotes_df['volatility_5'].isna().all():
                avg_volatility_after = float(quotes_df['volatility_5'].mean())
                volatility_change = ((avg_volatility_after - event_volatility) / event_volatility) * 100 if event_volatility > 0 else 0
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ö–æ–¥
            if price_change_pct > 2.0:
                outcome = 'POSITIVE'
            elif price_change_pct < -2.0:
                outcome = 'NEGATIVE'
            else:
                outcome = 'NEUTRAL'
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ sentiment —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º (–µ—Å–ª–∏ –µ—Å—Ç—å sentiment –≤ knowledge_base)
            sentiment_match = None
            try:
                with self.engine.connect() as conn:
                    # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –Ω–æ–≤–æ—Å—Ç—å –≤ knowledge_base
                    sentiment_query = text("""
                        SELECT sentiment_score
                        FROM knowledge_base
                        WHERE ticker = :ticker
                          AND ABS(EXTRACT(EPOCH FROM (ts - :event_ts))) < 3600
                          AND LEFT(content, 100) LIKE :content_prefix
                        LIMIT 1
                    """)
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
                    content_prefix = quotes_df.iloc[0].get('content', '')[:50] if not quotes_df.empty else ''
                    sentiment_result = conn.execute(
                        sentiment_query,
                        {
                            "ticker": ticker,
                            "event_ts": event_ts,
                            "content_prefix": f"%{content_prefix}%"
                        }
                    )
                    sentiment_row = sentiment_result.fetchone()
                    
                    if sentiment_row and sentiment_row[0] is not None:
                        sentiment_score = float(sentiment_row[0])
                        # Sentiment > 0.5 = –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π, < 0.5 = –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π
                        sentiment_positive = sentiment_score > 0.5
                        price_positive = price_change_pct > 0
                        sentiment_match = sentiment_positive == price_positive
            except Exception as e:
                logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å sentiment match: {e}")
            
            result = {
                'price_change_pct': round(price_change_pct, 2),
                'max_gain_pct': round(max_gain_pct, 2),
                'max_loss_pct': round(max_loss_pct, 2),
                'volatility_change': round(volatility_change, 2) if volatility_change is not None else None,
                'sentiment_match': sentiment_match,
                'outcome': outcome,
                'days_analyzed': len(quotes_df),
                'event_price': round(event_price, 2),
                'final_price': round(final_price, 2)
            }
            
            logger.debug(
                f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–∞ —Å–æ–±—ã—Ç–∏—è ID={event_id}: "
                f"–∏–∑–º–µ–Ω–µ–Ω–∏–µ {price_change_pct:.2f}%, –∏—Å—Ö–æ–¥ {outcome}"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ö–æ–¥–∞ —Å–æ–±—ã—Ç–∏—è ID={event_id}: {e}")
            return None
    
    def aggregate_patterns(self, similar_events: pd.DataFrame) -> Dict[str, Any]:
        """
        –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –∏—Å—Ö–æ–¥—ã –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–±—ã—Ç–∏–π
        
        Args:
            similar_events: DataFrame —Å –ø–æ—Ö–æ–∂–∏–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å outcome_json)
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏:
            {
                'avg_price_change': float,
                'success_rate': float,  # % —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ sentiment —Å–æ–≤–ø–∞–ª —Å –¥–≤–∏–∂–µ–Ω–∏–µ–º
                'avg_volatility_change': float,
                'typical_outcome': str,
                'confidence': float,  # –ù–∞—Å–∫–æ–ª—å–∫–æ —É–≤–µ—Ä–µ–Ω—ã –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–µ
                'sample_size': int
            }
        """
        if similar_events.empty:
            return {
                'avg_price_change': 0.0,
                'success_rate': 0.0,
                'avg_volatility_change': 0.0,
                'typical_outcome': 'NEUTRAL',
                'confidence': 0.0,
                'sample_size': 0
            }
        
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥—ã —Å–æ–±—ã—Ç–∏–π –∏–∑ –ë–î (outcome_json)
        event_ids = similar_events['id'].tolist()
        
        try:
            with self.engine.connect() as conn:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ outcome_json
                result = conn.execute(text("""
                    SELECT column_name 
                    FROM information_schema.columns 
                    WHERE table_name='trade_kb' AND column_name='outcome_json'
                """))
                has_outcome_json = result.fetchone() is not None
                
                if not has_outcome_json:
                    logger.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ outcome_json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ trade_kb, –∞–Ω–∞–ª–∏–∑ –∏—Å—Ö–æ–¥–æ–≤ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω")
                    return {
                        'avg_price_change': 0.0,
                        'success_rate': 0.0,
                        'avg_volatility_change': 0.0,
                        'typical_outcome': 'NEUTRAL',
                        'confidence': 0.0,
                        'sample_size': 0,
                        'note': 'outcome_json column missing'
                    }
                
                # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥—ã
                outcomes_query = text("""
                    SELECT outcome_json
                    FROM trade_kb
                    WHERE id = ANY(:event_ids)
                      AND outcome_json IS NOT NULL
                """)
                outcomes_result = conn.execute(
                    outcomes_query,
                    {"event_ids": event_ids}
                )
                
                outcomes = []
                for row in outcomes_result:
                    if row[0]:
                        import json
                        if isinstance(row[0], str):
                            outcomes.append(json.loads(row[0]))
                        else:
                            outcomes.append(row[0])
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ö–æ–¥–æ–≤: {e}")
            outcomes = []
        
        if not outcomes:
            logger.info("‚ÑπÔ∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–± –∏—Å—Ö–æ–¥–∞—Ö –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–±—ã—Ç–∏–π")
            return {
                'avg_price_change': 0.0,
                'success_rate': 0.0,
                'avg_volatility_change': 0.0,
                'typical_outcome': 'NEUTRAL',
                'confidence': 0.0,
                'sample_size': 0
            }
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        price_changes = [o.get('price_change_pct', 0) for o in outcomes if o.get('price_change_pct') is not None]
        sentiment_matches = [o.get('sentiment_match') for o in outcomes if o.get('sentiment_match') is not None]
        volatility_changes = [o.get('volatility_change', 0) for o in outcomes if o.get('volatility_change') is not None]
        outcomes_list = [o.get('outcome') for o in outcomes if o.get('outcome')]
        
        avg_price_change = np.mean(price_changes) if price_changes else 0.0
        success_rate = sum(sentiment_matches) / len(sentiment_matches) if sentiment_matches else 0.0
        avg_volatility_change = np.mean(volatility_changes) if volatility_changes else 0.0
        
        # –¢–∏–ø–∏—á–Ω—ã–π –∏—Å—Ö–æ–¥ (–Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã–π)
        from collections import Counter
        outcome_counts = Counter(outcomes_list)
        typical_outcome = outcome_counts.most_common(1)[0][0] if outcome_counts else 'NEUTRAL'
        
        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ –∏—Å—Ö–æ–¥–æ–≤)
        sample_size = len(outcomes)
        consistency = max(outcome_counts.values()) / sample_size if sample_size > 0 else 0.0
        confidence = min(0.95, consistency * (1 + np.log10(sample_size + 1) / 10))
        
        result = {
            'avg_price_change': round(avg_price_change, 2),
            'success_rate': round(success_rate, 3),
            'avg_volatility_change': round(avg_volatility_change, 2),
            'typical_outcome': typical_outcome,
            'confidence': round(confidence, 3),
            'sample_size': sample_size
        }
        
        logger.info(
            f"üìä –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: "
            f"—Å—Ä–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ {avg_price_change:.2f}%, "
            f"success rate {success_rate:.1%}, "
            f"—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence:.2f} (n={sample_size})"
        )
        
        return result
    
    def update_event_outcome(
        self,
        event_id: int,
        outcome: Dict[str, Any]
    ) -> bool:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç outcome_json –¥–ª—è —Å–æ–±—ã—Ç–∏—è –≤ trade_kb
        
        Args:
            event_id: ID —Å–æ–±—ã—Ç–∏—è
            outcome: –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏—Å—Ö–æ–¥–∞
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            import json
            
            with self.engine.begin() as conn:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏
                result = conn.execute(text("""
                    SELECT column_name 
                    FROM information_schema.columns 
                    WHERE table_name='trade_kb' AND column_name='outcome_json'
                """))
                if not result.fetchone():
                    # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–æ–Ω–∫—É –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
                    conn.execute(text("ALTER TABLE trade_kb ADD COLUMN outcome_json JSONB"))
                    logger.info("‚úÖ –ö–æ–ª–æ–Ω–∫–∞ outcome_json –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ trade_kb")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º outcome_json
                conn.execute(
                    text("""
                        UPDATE trade_kb
                        SET outcome_json = :outcome_json
                        WHERE id = :event_id
                    """),
                    {
                        "event_id": event_id,
                        "outcome_json": json.dumps(outcome)
                    }
                )
            
            logger.debug(f"‚úÖ –ò—Å—Ö–æ–¥ —Å–æ–±—ã—Ç–∏—è ID={event_id} –æ–±–Ω–æ–≤–ª–µ–Ω")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏—Å—Ö–æ–¥–∞ —Å–æ–±—ã—Ç–∏—è ID={event_id}: {e}")
            return False


if __name__ == "__main__":
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # –¢–µ—Å—Ç
    analyzer = NewsImpactAnalyzer()
    
    # –ü—Ä–∏–º–µ—Ä –∞–Ω–∞–ª–∏–∑–∞ –∏—Å—Ö–æ–¥–∞ —Å–æ–±—ã—Ç–∏—è
    # (—Ç—Ä–µ–±—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–æ–±—ã—Ç–∏–µ –≤ trade_kb –∏ –∫–æ—Ç–∏—Ä–æ–≤–∫–∏ –≤ quotes)
    # outcome = analyzer.analyze_event_outcome(event_id=1, ticker="MSFT", days_after=7)
    # print(f"–ò—Å—Ö–æ–¥ —Å–æ–±—ã—Ç–∏—è: {outcome}")
