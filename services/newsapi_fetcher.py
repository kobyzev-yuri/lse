"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ NewsAPI
"""

import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import requests
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from sqlalchemy import create_engine, text

from config_loader import get_database_url, get_config_value

logger = logging.getLogger(__name__)


def get_api_key() -> Optional[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç API –∫–ª—é—á NewsAPI –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞"""
    return get_config_value('NEWSAPI_KEY', None)


def fetch_newsapi_articles(
    api_key: str, 
    query: str, 
    sources: str = 'reuters,bloomberg,financial-times',
    language: str = 'en',
    days_back: int = 1
) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ NewsAPI
    
    Args:
        api_key: API –∫–ª—é—á NewsAPI
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Federal Reserve")
        sources: –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
        language: –Ø–∑—ã–∫ (en)
        days_back: –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –∏—Å–∫–∞—Ç—å
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏
    """
    url = "https://newsapi.org/v2/everything"
    
    from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
    
    params = {
        'q': query,
        'sources': sources,
        'language': language,
        'sortBy': 'publishedAt',
        'apiKey': api_key,
        'from': from_date,
        'pageSize': 100  # –ú–∞–∫—Å–∏–º—É–º –¥–ª—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ tier
    }
    
    try:
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        if data.get('status') != 'ok':
            logger.error(f"‚ùå NewsAPI –æ—à–∏–±–∫–∞: {data.get('message', 'Unknown error')}")
            return []
        
        articles = []
        for article in data.get('articles', []):
            try:
                # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É
                published_time = None
                if article.get('publishedAt'):
                    try:
                        published_time = datetime.fromisoformat(
                            article['publishedAt'].replace('Z', '+00:00')
                        )
                    except:
                        published_time = datetime.now()
                
                articles.append({
                    'title': article.get('title', ''),
                    'content': (article.get('description', '') or '') + '\n\n' + (article.get('content', '') or ''),
                    'source': article.get('source', {}).get('name', 'Unknown'),
                    'published': published_time or datetime.now(),
                    'url': article.get('url', ''),
                    'author': article.get('author', '')
                })
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç–∞—Ç—å–∏: {e}")
                continue
        
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ NewsAPI –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}'")
        return articles
        
    except requests.exceptions.RequestException as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ NewsAPI: {e}")
        return []
    except Exception as e:
        logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π: {e}")
        return []


def fetch_macro_news(api_key: str) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –º–∞–∫—Ä–æ-–Ω–æ–≤–æ—Å—Ç–∏ (Fed, ECB, BoE, —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
    
    Args:
        api_key: API –∫–ª—é—á NewsAPI
        
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
    """
    queries = [
        'Federal Reserve OR FOMC OR Fed rate',
        'European Central Bank OR ECB',
        'Bank of England OR BoE',
        'CPI OR inflation OR unemployment OR GDP',
        'interest rate OR monetary policy'
    ]
    
    all_news = []
    for query in queries:
        logger.info(f"üîç –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π: {query}")
        news = fetch_newsapi_articles(api_key, query, days_back=2)
        all_news.extend(news)
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ URL
    seen_urls = set()
    unique_news = []
    for item in all_news:
        if item.get('url') and item['url'] not in seen_urls:
            seen_urls.add(item['url'])
            unique_news.append(item)
    
    logger.info(f"‚úÖ –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–∞–∫—Ä–æ-–Ω–æ–≤–æ—Å—Ç–µ–π: {len(unique_news)}")
    return unique_news


def save_news_to_db(news_items: List[Dict], ticker: str = 'MACRO', event_type: str = 'NEWS'):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ NewsAPI –≤ –ë–î
    
    Args:
        news_items: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
        ticker: –¢–∏–∫–µ—Ä –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é MACRO)
        event_type: –¢–∏–ø —Å–æ–±—ã—Ç–∏—è
    """
    if not news_items:
        return
    
    db_url = get_database_url()
    engine = create_engine(db_url)
    
    saved_count = 0
    skipped_count = 0
    
    with engine.begin() as conn:
        for item in news_items:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ URL
                if item.get('url'):
                    existing = conn.execute(
                        text("""
                            SELECT id FROM knowledge_base 
                            WHERE link = :url
                        """),
                        {"url": item['url']}
                    ).fetchone()
                    
                    if existing:
                        skipped_count += 1
                        continue
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–≥–∏–æ–Ω –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫—É/–∫–æ–Ω—Ç–µ–Ω—Ç—É
                region = None
                source_lower = item.get('source', '').lower()
                content_lower = item.get('content', '').lower()
                
                if 'federal reserve' in content_lower or 'fomc' in content_lower or 'fed' in content_lower:
                    region = 'USA'
                    ticker = 'US_MACRO'
                elif 'ecb' in content_lower or 'european central bank' in content_lower:
                    region = 'EU'
                elif 'bank of england' in content_lower or 'boe' in content_lower:
                    region = 'UK'
                
                conn.execute(
                    text("""
                        INSERT INTO knowledge_base 
                        (ts, ticker, source, content, link, event_type, region, importance)
                        VALUES (:ts, :ticker, :source, :content, :link, :event_type, :region, :importance)
                    """),
                    {
                        "ts": item['published'],
                        "ticker": ticker,
                        "source": item.get('source', 'NewsAPI'),
                        "content": f"{item.get('title', '')}\n\n{item.get('content', '')}",
                        "link": item.get('url', ''),
                        "event_type": event_type,
                        "region": region,
                        "importance": "MEDIUM"  # –ú–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏
                    }
                )
                saved_count += 1
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–∏: {e}")
    
    logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ NewsAPI, –ø—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {skipped_count}")
    engine.dispose()


def fetch_and_save_newsapi_news():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ NewsAPI –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –ë–î
    """
    api_key = get_api_key()
    if not api_key:
        logger.warning("‚ö†Ô∏è NEWSAPI_KEY –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –≤ config.env, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º NewsAPI")
        return
    
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ NewsAPI")
    
    # –ü–æ–ª—É—á–∞–µ–º –º–∞–∫—Ä–æ-–Ω–æ–≤–æ—Å—Ç–∏
    macro_news = fetch_macro_news(api_key)
    if macro_news:
        save_news_to_db(macro_news, ticker='MACRO', event_type='MACRO_NEWS')
    
    logger.info("‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –ø–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ NewsAPI")


if __name__ == "__main__":
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    fetch_and_save_newsapi_news()
