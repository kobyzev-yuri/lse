# –ü–ª–∞–Ω –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Must-List –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –Ω–æ–≤–æ—Å—Ç–µ–π

## üéØ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è

### –§–∞–∑–∞ 1: –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (1-2 –¥–Ω—è) - –ë–ï–°–ü–õ–ê–¢–ù–û ‚úÖ –í–´–ü–û–õ–ù–ï–ù–û
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** –í—ã—Å–æ–∫–∏–π  
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** –ù–∏–∑–∫–∞—è  
**–°—Ç–æ–∏–º–æ—Å—Ç—å:** $0

1. ‚úÖ **RSS —Ñ–∏–¥—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤** (Fed, BoE, ECB, BoJ) ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û
   - –ù–µ —Ç—Ä–µ–±—É—é—Ç API –∫–ª—é—á–µ–π
   - –°—Ç–∞–±–∏–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
   - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ `feedparser`
   - **–§–∞–π–ª:** `services/rss_news_fetcher.py`

2. ‚úÖ **Economic Calendar —á–µ—Ä–µ–∑ Investing.com** (web scraping) ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û
   - –ë–µ—Å–ø–ª–∞—Ç–Ω–æ
   - –£–∂–µ –µ—Å—Ç—å –æ–ø—ã—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ (–ì–∏–¥—Ä–∞ –¥–ª—è Telegram)
   - –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥
   - **–§–∞–π–ª:** `services/investing_calendar_parser.py`

### –§–∞–∑–∞ 2: Earnings –∏ –Ω–æ–≤–æ—Å—Ç–∏ (2-3 –¥–Ω—è) - –ë–ï–°–ü–õ–ê–¢–ù–´–ô TIER ‚úÖ –í–´–ü–û–õ–ù–ï–ù–û
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** –í—ã—Å–æ–∫–∏–π  
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** –°—Ä–µ–¥–Ω—è—è  
**–°—Ç–æ–∏–º–æ—Å—Ç—å:** $0 (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –ª–∏–º–∏—Ç—ã)

3. ‚úÖ **Alpha Vantage API** (Earnings Calendar + News Sentiment + Economic Indicators + Technical Indicators) ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û
   - –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π tier: 5 –∑–∞–ø—Ä–æ—Å–æ–≤/–º–∏–Ω—É—Ç—É, 500/–¥–µ–Ω—å
   - –¢—Ä–µ–±—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –∏ API –∫–ª—é—á
   - **–§–∞–π–ª:** `services/alphavantage_fetcher.py`
   - **–¢—Ä–µ–±—É–µ—Ç:** `ALPHAVANTAGE_KEY` –≤ config.env
   - **Economic Indicators:** CPI, GDP, Federal Funds Rate, Treasury Yield, Unemployment (—Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `knowledge_base` —Å `event_type='ECONOMIC_INDICATOR'`)
   - **Technical Indicators:** RSI, MACD, Bollinger Bands, ADX, Stochastic (–æ–±–Ω–æ–≤–ª—è—é—Ç —Ç–∞–±–ª–∏—Ü—É `quotes`)

4. ‚úÖ **NewsAPI** (–∞–≥—Ä–µ–≥–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π) ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û
   - –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π tier: 100 –∑–∞–ø—Ä–æ—Å–æ–≤/–¥–µ–Ω—å
   - –¢—Ä–µ–±—É–µ—Ç —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –∏ API –∫–ª—é—á
   - **–§–∞–π–ª:** `services/newsapi_fetcher.py`
   - **–¢—Ä–µ–±—É–µ—Ç:** `NEWSAPI_KEY` –≤ config.env

### –§–∞–∑–∞ 3: –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (3-5 –¥–Ω–µ–π) - –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** –°—Ä–µ–¥–Ω–∏–π  
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** –í—ã—Å–æ–∫–∞—è  
**–°—Ç–æ–∏–º–æ—Å—Ç—å:** –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞

5. ‚ö†Ô∏è **Trading Economics API** (—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π –∫–∞–ª–µ–Ω–¥–∞—Ä—å)
   - –ü–ª–∞—Ç–Ω—ã–π (–æ—Ç $50/–º–µ—Å—è—Ü)
   - –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ Investing.com scraping

6. ‚ö†Ô∏è **Bloomberg Terminal API** (–∏–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã)
   - –û—á–µ–Ω—å –¥–æ—Ä–æ–≥–æ ($2000+/–º–µ—Å—è—Ü)
   - –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ø–∞—Ä—Å–∏–Ω–≥ –ø—É–±–ª–∏—á–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤

---

## üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Å –§–∞–∑—ã 1: RSS —Ñ–∏–¥—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤

### –®–∞–≥ 1: –°–æ–∑–¥–∞–µ–º –º–æ–¥—É–ª—å –¥–ª—è RSS –ø–∞—Ä—Å–∏–Ω–≥–∞

**–§–∞–π–ª:** `services/rss_news_fetcher.py`

```python
"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ RSS —Ñ–∏–¥–æ–≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤
"""

import feedparser
import logging
from datetime import datetime
from typing import List, Dict, Optional
from sqlalchemy import create_engine, text

from config_loader import get_database_url

logger = logging.getLogger(__name__)


# RSS —Ñ–∏–¥—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤
RSS_FEEDS = {
    'FOMC_STATEMENT': {
        'url': 'https://www.federalreserve.gov/feeds/press_all.xml',
        'region': 'USA',
        'event_type': 'FOMC_STATEMENT',
        'importance': 'HIGH'
    },
    'FOMC_SPEECH': {
        'url': 'https://www.federalreserve.gov/feeds/speeches.xml',
        'region': 'USA',
        'event_type': 'FOMC_SPEECH',
        'importance': 'HIGH'
    },
    'FOMC_MINUTES': {
        'url': 'https://www.federalreserve.gov/feeds/fomcminutes.xml',
        'region': 'USA',
        'event_type': 'FOMC_MINUTES',
        'importance': 'HIGH'
    },
    'BOE_STATEMENT': {
        'url': 'https://www.bankofengland.co.uk/rss',
        'region': 'UK',
        'event_type': 'BOE_STATEMENT',
        'importance': 'HIGH'
    },
    'ECB_STATEMENT': {
        'url': 'https://www.ecb.europa.eu/rss/press.html',
        'region': 'EU',
        'event_type': 'ECB_STATEMENT',
        'importance': 'HIGH'
    },
    'BOJ_STATEMENT': {
        'url': 'https://www.boj.or.jp/en/announcements/press/index.htm/rss',
        'region': 'Japan',
        'event_type': 'BOJ_STATEMENT',
        'importance': 'HIGH'
    }
}


def parse_rss_feed(feed_config: Dict) -> List[Dict]:
    """
    –ü–∞—Ä—Å–∏—Ç RSS —Ñ–∏–¥ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π
    
    Args:
        feed_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ñ–∏–¥–∞ (url, region, event_type, importance)
        
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏
    """
    url = feed_config['url']
    region = feed_config['region']
    event_type = feed_config['event_type']
    importance = feed_config['importance']
    
    try:
        feed = feedparser.parse(url)
        
        if feed.bozo:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS —Ñ–∏–¥–∞ {url}: {feed.bozo_exception}")
            return []
        
        items = []
        for entry in feed.entries:
            # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
            published_time = None
            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                published_time = datetime(*entry.published_parsed[:6])
            elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                published_time = datetime(*entry.updated_parsed[:6])
            else:
                published_time = datetime.now()
            
            item = {
                'title': entry.title,
                'link': entry.link,
                'content': entry.summary if hasattr(entry, 'summary') else entry.title,
                'published': published_time,
                'ticker': 'US_MACRO' if region == 'USA' else 'MACRO',
                'source': f"{region} Central Bank",
                'event_type': event_type,
                'region': region,
                'importance': importance
            }
            items.append(item)
        
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(items)} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {event_type}")
        return items
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ RSS —Ñ–∏–¥–∞ {url}: {e}")
        return []


def fetch_all_rss_feeds() -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ –≤—Å–µ—Ö RSS —Ñ–∏–¥–æ–≤
    
    Returns:
        –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
    """
    all_news = []
    
    for feed_name, feed_config in RSS_FEEDS.items():
        logger.info(f"üì° –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {feed_name}...")
        news = parse_rss_feed(feed_config)
        all_news.extend(news)
    
    logger.info(f"‚úÖ –í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ {len(all_news)} –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ RSS —Ñ–∏–¥–æ–≤")
    return all_news


def save_news_to_db(news_items: List[Dict], check_duplicates: bool = True):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    
    Args:
        news_items: –°–ø–∏—Å–æ–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        check_duplicates: –ü—Ä–æ–≤–µ—Ä—è—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ link
    """
    if not news_items:
        logger.info("‚ÑπÔ∏è –ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        return
    
    db_url = get_database_url()
    engine = create_engine(db_url)
    
    saved_count = 0
    skipped_count = 0
    
    with engine.begin() as conn:
        for item in news_items:
            try:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ link (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞)
                if check_duplicates:
                    existing = conn.execute(
                        text("""
                            SELECT id FROM knowledge_base 
                            WHERE source = :source 
                            AND link = :link
                        """),
                        {"source": item.get('source', ''), "link": item.get('link', '')}
                    ).fetchone()
                    
                    if existing:
                        skipped_count += 1
                        continue
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤–æ—Å—Ç—å
                conn.execute(
                    text("""
                        INSERT INTO knowledge_base 
                        (ts, ticker, source, content, event_type, region, importance)
                        VALUES (:ts, :ticker, :source, :content, :event_type, :region, :importance)
                    """),
                    {
                        "ts": item['published'],
                        "ticker": item['ticker'],
                        "source": item['source'],
                        "content": f"{item['title']}\n\n{item['content']}\n\nLink: {item['link']}",
                        "event_type": item.get('event_type'),
                        "region": item.get('region'),
                        "importance": item.get('importance')
                    }
                )
                saved_count += 1
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–∏ '{item.get('title', '')[:50]}...': {e}")
    
    logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved_count} –Ω–æ–≤–æ—Å—Ç–µ–π, –ø—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {skipped_count}")
    engine.dispose()


def fetch_and_save_rss_news():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ RSS –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –ë–î
    """
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ RSS —Ñ–∏–¥–æ–≤ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤")
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏
    news_items = fetch_all_rss_feeds()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
    if news_items:
        save_news_to_db(news_items)
    
    logger.info("‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ –ø–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ RSS —Ñ–∏–¥–æ–≤")


if __name__ == "__main__":
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    fetch_and_save_rss_news()
```

### –®–∞–≥ 2: –û–±–Ω–æ–≤–ª—è–µ–º requirements.txt

```bash
# –î–æ–±–∞–≤–∏—Ç—å –≤ requirements.txt:
feedparser>=6.0.10
```

### –®–∞–≥ 3: –°–æ–∑–¥–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏—é –ë–î –¥–ª—è –Ω–æ–≤—ã—Ö –ø–æ–ª–µ–π

**–§–∞–π–ª:** `scripts/migrate_add_news_fields.py`

```python
"""
–ú–∏–≥—Ä–∞—Ü–∏—è: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª–µ–π event_type, region, importance –≤ knowledge_base
"""

from sqlalchemy import create_engine, text
from config_loader import get_database_url
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def migrate():
    """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ knowledge_base"""
    db_url = get_database_url()
    engine = create_engine(db_url)
    
    with engine.begin() as conn:
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        try:
            conn.execute(text("""
                ALTER TABLE knowledge_base 
                ADD COLUMN IF NOT EXISTS event_type VARCHAR(50)
            """))
            logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ event_type")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ event_type: {e}")
        
        try:
            conn.execute(text("""
                ALTER TABLE knowledge_base 
                ADD COLUMN IF NOT EXISTS region VARCHAR(20)
            """))
            logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ region")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ region: {e}")
        
        try:
            conn.execute(text("""
                ALTER TABLE knowledge_base 
                ADD COLUMN IF NOT EXISTS importance VARCHAR(10)
            """))
            logger.info("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ importance")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ importance: {e}")
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
        try:
            conn.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_kb_event_type 
                ON knowledge_base(event_type)
            """))
            logger.info("‚úÖ –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å idx_kb_event_type")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å event_type: {e}")
        
        try:
            conn.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_kb_region 
                ON knowledge_base(region)
            """))
            logger.info("‚úÖ –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å idx_kb_region")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å region: {e}")
    
    logger.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
    engine.dispose()


if __name__ == "__main__":
    migrate()
```

### –®–∞–≥ 4: –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install feedparser>=6.0.10

# 2. –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é
python scripts/migrate_add_news_fields.py

# 3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å RSS –ø–∞—Ä—Å–µ—Ä
python services/rss_news_fetcher.py
```

---

## üìÖ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ (–§–∞–∑–∞ 2)

### Alpha Vantage API - Earnings Calendar

**–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è:**
1. –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ https://www.alphavantage.co/support/#api-key
2. –ó–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ–æ—Ä–º—É (–±–µ—Å–ø–ª–∞—Ç–Ω–æ)
3. –ü–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
# services/alphavantage_fetcher.py
import requests
import csv
from io import StringIO

def fetch_earnings_calendar(api_key: str, symbol: str = None):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∫–∞–ª–µ–Ω–¥–∞—Ä—å earnings —á–µ—Ä–µ–∑ Alpha Vantage
    
    Args:
        api_key: API –∫–ª—é—á Alpha Vantage
        symbol: –¢–∏–∫–µ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ None - –≤—Å–µ)
    """
    url = "https://www.alphavantage.co/query"
    params = {
        'function': 'EARNINGS_CALENDAR',
        'apikey': api_key
    }
    if symbol:
        params['symbol'] = symbol
    
    response = requests.get(url, params=params)
    
    # Alpha Vantage –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç CSV
    csv_data = response.text
    reader = csv.DictReader(StringIO(csv_data))
    
    earnings = []
    for row in reader:
        earnings.append({
            'symbol': row.get('symbol'),
            'reportDate': row.get('reportDate'),
            'estimate': row.get('estimate'),
            'currency': row.get('currency')
        })
    
    return earnings
```

### NewsAPI - –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π

**–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è:**
1. –ü–µ—Ä–µ–π—Ç–∏ –Ω–∞ https://newsapi.org/register
2. –ó–∞–ø–æ–ª–Ω–∏—Ç—å —Ñ–æ—Ä–º—É (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–π tier: 100 –∑–∞–ø—Ä–æ—Å–æ–≤/–¥–µ–Ω—å)
3. –ü–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
# services/newsapi_fetcher.py
import requests
from datetime import datetime, timedelta

def fetch_newsapi_articles(api_key: str, query: str, sources: str = 'reuters,bloomberg'):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ NewsAPI
    
    Args:
        api_key: API –∫–ª—é—á NewsAPI
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Federal Reserve")
        sources: –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
    """
    url = "https://newsapi.org/v2/everything"
    params = {
        'q': query,
        'sources': sources,
        'language': 'en',
        'sortBy': 'publishedAt',
        'apiKey': api_key,
        'from': (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
    }
    
    response = requests.get(url, params=params)
    data = response.json()
    
    articles = []
    for article in data.get('articles', []):
        articles.append({
            'title': article['title'],
            'content': article.get('description', '') + '\n\n' + article.get('content', ''),
            'source': article['source']['name'],
            'published': datetime.fromisoformat(article['publishedAt'].replace('Z', '+00:00')),
            'url': article['url']
        })
    
    return articles
```

---

## üîÑ –ü–ª–∞–Ω –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Cron –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ß–µ—Ä–µ–∑ –æ–±—â–∏–π —Å–∫—Ä–∏–ø—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–ó–∞–¥–∞—á–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ `setup_cron.sh`. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–¥–∏–Ω —Ä–∞–∑:

```bash
cd /home/cnn/lse
./setup_cron.sh
```

–ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ:
- **–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω:** –µ–∂–µ–¥–Ω–µ–≤–Ω–æ –≤ 22:00
- **–¢–æ—Ä–≥–æ–≤—ã–π —Ü–∏–∫–ª:** 9:00, 13:00, 17:00 (–ø–Ω‚Äì–ø—Ç)
- **–ù–æ–≤–æ—Å—Ç–∏:** –∫–∞–∂–¥—ã–π —á–∞—Å –≤ :00 (RSS, NewsAPI, Alpha Vantage)

–õ–æ–≥ –Ω–æ–≤–æ—Å—Ç–µ–π: `logs/news_fetch.log`

### –í–∞—Ä–∏–∞–Ω—Ç 2: –î–æ–±–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤–æ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é

```bash
crontab -e
```

–î–æ–±–∞–≤—å—Ç–µ —Å—Ç—Ä–æ–∫—É (–ø–æ–¥—Å—Ç–∞–≤—å—Ç–µ —Å–≤–æ–π –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –∏ python):

```bash
# –ù–æ–≤–æ—Å—Ç–∏ LSE ‚Äî –∫–∞–∂–¥—ã–π —á–∞—Å
0 * * * * cd /home/cnn/lse && /usr/bin/python3 scripts/fetch_news_cron.py >> /home/cnn/lse/logs/news_fetch.log 2>&1
```

–ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ conda env **py11** (–¥–ª—è feedparser), —É–∫–∞–∂–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ python —ç—Ç–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è:

```bash
0 * * * * cd /home/cnn/lse && /path/to/anaconda3/envs/py11/bin/python scripts/fetch_news_cron.py >> /home/cnn/lse/logs/news_fetch.log 2>&1
```

–£–∑–Ω–∞—Ç—å –ø—É—Ç—å: `conda activate py11 && which python`

### –ü—Ä–æ–≤–µ—Ä–∫–∞

```bash
# –°–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
crontab -l

# –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ (—Ç–µ—Å—Ç)
cd /home/cnn/lse && python3 scripts/fetch_news_cron.py

# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–∞
tail -f logs/news_fetch.log
```

### –°–∫—Ä–∏–ø—Ç

**–§–∞–π–ª:** `scripts/fetch_news_cron.py` ‚Äî –ø–æ –æ—á–µ—Ä–µ–¥–∏ –≤—ã–∑—ã–≤–∞–µ—Ç RSS, Investing.com, Alpha Vantage, NewsAPI –∏ –ø–∏—à–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ë–î –∏ –≤ –ª–æ–≥.

---

## ‚úÖ –ß–µ–∫–ª–∏—Å—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –§–∞–∑–∞ 1 (RSS —Ñ–∏–¥—ã) - 1-2 –¥–Ω—è ‚úÖ –í–´–ü–û–õ–ù–ï–ù–û
- [x] –°–æ–∑–¥–∞—Ç—å `services/rss_news_fetcher.py` ‚úÖ
- [x] –î–æ–±–∞–≤–∏—Ç—å `feedparser` –≤ `requirements.txt` ‚úÖ
- [x] –°–æ–∑–¥–∞—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é `scripts/migrate_add_news_fields.py` ‚úÖ
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é (—Ç—Ä–µ–±—É–µ—Ç—Å—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ)
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ RSS —Ñ–∏–¥–æ–≤ (—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
- [ ] –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –≤ –ë–î (—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
- [x] –î–æ–±–∞–≤–∏—Ç—å cron –∑–∞–¥–∞—á—É –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ‚úÖ (—á–µ—Ä–µ–∑ ./setup_cron.sh)

### –§–∞–∑–∞ 2 (API –∏—Å—Ç–æ—á–Ω–∏–∫–∏) - 2-3 –¥–Ω—è ‚úÖ –í–´–ü–û–õ–ù–ï–ù–û
- [ ] –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ Alpha Vantage, –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á (—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è)
- [x] –°–æ–∑–¥–∞—Ç—å `services/alphavantage_fetcher.py` ‚úÖ
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ Earnings Calendar (—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å API –∫–ª—é—á–æ–º)
- [ ] –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤ NewsAPI, –ø–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á (—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è)
- [x] –°–æ–∑–¥–∞—Ç—å `services/newsapi_fetcher.py` ‚úÖ
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π (—Ç—Ä–µ–±—É–µ—Ç—Å—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å API –∫–ª—é—á–æ–º)
- [x] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ `scripts/fetch_news_cron.py` ‚úÖ

### –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ ‚úÖ –í–´–ü–û–õ–ù–ï–ù–û
- [x] –°–æ–∑–¥–∞—Ç—å `services/investing_calendar_parser.py` ‚úÖ
- [x] –°–æ–∑–¥–∞—Ç—å `scripts/fetch_news_cron.py` –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ ‚úÖ

### –§–∞–∑–∞ 3 (Investing.com scraping) - 2-3 –¥–Ω—è
- [ ] –ò–∑—É—á–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É Investing.com Economic Calendar
- [ ] –°–æ–∑–¥–∞—Ç—å `services/investing_calendar_parser.py`
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
- [ ] –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –∏ retry –ª–æ–≥–∏–∫—É
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ cron

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

**–õ–æ–≥–∏:**
- `logs/news_fetch.log` - –æ–±—â–∏–π –ª–æ–≥ –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π
- `logs/news_cron.log` - –ª–æ–≥ cron –∑–∞–¥–∞—á

**–ú–µ—Ç—Ä–∏–∫–∏:**
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–µ–Ω—å –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)
- –û—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞/API –∑–∞–ø—Ä–æ—Å–æ–≤

---

## üìù –ò—Ç–æ–≥–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (2026-02-19)

1. **RSS —Ñ–∏–¥—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤** ‚úÖ
   - –§–∞–π–ª: `services/rss_news_fetcher.py`
   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: Fed (FOMC), BoE, ECB, BoJ
   - –ù–µ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–µ–π

2. **Investing.com Economic Calendar** ‚úÖ
   - –§–∞–π–ª: `services/investing_calendar_parser.py`
   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: USA, UK, EU, Japan, China, Switzerland
   - Web scraping —á–µ—Ä–µ–∑ BeautifulSoup

3. **Alpha Vantage API** ‚úÖ
   - –§–∞–π–ª: `services/alphavantage_fetcher.py`
   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: 
     - Earnings Calendar (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ `knowledge_base`)
     - News Sentiment (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ `knowledge_base` —Å sentiment_score)
     - Economic Indicators: CPI, GDP, Federal Funds Rate, Treasury Yield, Unemployment (—Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `knowledge_base` —Å `event_type='ECONOMIC_INDICATOR'`)
     - Technical Indicators: RSI, MACD, Bollinger Bands, ADX, Stochastic (–æ–±–Ω–æ–≤–ª—è—é—Ç —Ç–∞–±–ª–∏—Ü—É `quotes`)
   - –¢—Ä–µ–±—É–µ—Ç: `ALPHAVANTAGE_KEY` –≤ config.env
   - –ù–∞—Å—Ç—Ä–æ–π–∫–∏: `ALPHAVANTAGE_FETCH_ECONOMIC=true`, `ALPHAVANTAGE_FETCH_TECHNICAL=true` (–≤ config.env)

4. **NewsAPI** ‚úÖ
   - –§–∞–π–ª: `services/newsapi_fetcher.py`
   - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: –º–∞–∫—Ä–æ-–Ω–æ–≤–æ—Å—Ç–∏, –∞–≥—Ä–µ–≥–∞—Ü–∏—è –∏–∑ Reuters/Bloomberg
   - –¢—Ä–µ–±—É–µ—Ç: `NEWSAPI_KEY` –≤ config.env

5. **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è** ‚úÖ
   - –§–∞–π–ª: `scripts/fetch_news_cron.py`
   - –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –æ–¥–∏–Ω —Å–∫—Ä–∏–ø—Ç

6. **–ú–∏–≥—Ä–∞—Ü–∏—è –ë–î** ‚úÖ
   - –§–∞–π–ª: `scripts/migrate_add_news_fields.py`
   - –î–æ–±–∞–≤–ª—è–µ—Ç: event_type, region, importance, link

### üîß –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. **–ó–∞–ø—É—Å—Ç–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é –ë–î:**
   ```bash
   python scripts/migrate_add_news_fields.py
   ```

2. **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:**
   ```bash
   pip install feedparser>=6.0.10 lxml>=4.9.0
   ```

3. **–ü–æ–ª—É—á–∏—Ç—å API –∫–ª—é—á–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**
   - Alpha Vantage: https://www.alphavantage.co/support/#api-key
   - NewsAPI: https://newsapi.org/register
   - –î–æ–±–∞–≤–∏—Ç—å –≤ `config.env`:
     ```env
     ALPHAVANTAGE_KEY=your_key_here
     NEWSAPI_KEY=your_key_here
     ```

4. **–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥:**
   ```bash
   # RSS —Ñ–∏–¥—ã (—Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ API –∫–ª—é—á–µ–π)
   python services/rss_news_fetcher.py
   
   # Investing.com –∫–∞–ª–µ–Ω–¥–∞—Ä—å
   python services/investing_calendar_parser.py
   
   # Alpha Vantage (—Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á)
   python services/alphavantage_fetcher.py
   
   # NewsAPI (—Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á)
   python services/newsapi_fetcher.py
   
   # –í—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å—Ä–∞–∑—É
   python scripts/fetch_news_cron.py
   ```

5. **–ù–∞—Å—Ç—Ä–æ–∏—Ç—å cron:**
   ```bash
   ./setup_cron.sh
   ```
   –ó–∞–¥–∞—á–∞ –Ω–æ–≤–æ—Å—Ç–µ–π (–∫–∞–∂–¥—ã–π —á–∞—Å) –≤—Ö–æ–¥–∏—Ç –≤ —Å–∫—Ä–∏–ø—Ç. –°–º. —Ä–∞–∑–¥–µ–ª ¬´–ü–ª–∞–Ω –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Cron –¥–ª—è –Ω–æ–≤–æ—Å—Ç–µ–π¬ª –≤—ã—à–µ.

### üìä –ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å

- [x] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å API –∫–ª—é—á –¥–ª—è NewsAPI ‚úÖ (–¥–æ–±–∞–≤–ª–µ–Ω –≤ config.env)
- [x] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª–∏ (RSS, NewsAPI, Alpha Vantage —Ä–∞–±–æ—Ç–∞—é—Ç) ‚úÖ
- [x] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å API –∫–ª—é—á –¥–ª—è Alpha Vantage ‚úÖ
- [ ] –î–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –∏ retry –ª–æ–≥–∏–∫—É
- [x] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å cron: –∑–∞–ø—É—Å—Ç–∏—Ç—å `./setup_cron.sh` ‚Äî –∑–∞–¥–∞—á–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–æ–±–∞–≤–ª–µ–Ω–∞ (–∫–∞–∂–¥—ã–π —á–∞—Å)
- [ ] –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å LLM –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ impact (—Å–º. NEWS_INTEGRATION_PLAN.md)

### üß™ –°—Ç–∞—Ç—É—Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

–°–º. [NEWS_TESTING_STATUS.md](NEWS_TESTING_STATUS.md) –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞.

### üß™ –ö–∞–∫ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è (–ø–æ—Å–ª–µ –ø—Ä–∞–≤–æ–∫)

–ò–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞ (`~/lse`), —Å –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä `conda activate py11`):

1. **–í—Å—ë —Å—Ä–∞–∑—É (–∫–∞–∫ –≤ cron):**
   ```bash
   python scripts/fetch_news_cron.py
   ```
   –õ–æ–≥–∏ –ø–∏—à—É—Ç—Å—è –≤ –∫–æ–Ω—Å–æ–ª—å –∏ –≤ `logs/news_fetch.log`.

2. **–¢–æ–ª—å–∫–æ Alpha Vantage** (earnings + –Ω–æ–≤–æ—Å—Ç–∏ + —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ + —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã):
   ```bash
   python services/alphavantage_fetcher.py
   ```
   –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–∏–∫–µ—Ä—ã `MSFT`, `SNDK`, `MU`. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤ –ª–æ–≥–∞—Ö: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö earnings, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã, –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –≤ `quotes`.

3. **–¢–æ–ª—å–∫–æ Investing.com –∫–∞–ª–µ–Ω–¥–∞—Ä—å:**
   ```bash
   python services/investing_calendar_parser.py
   ```
   –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å HTML –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞:
   ```bash
   INVESTING_CALENDAR_DEBUG_HTML=1 python services/investing_calendar_parser.py
   ```
   –§–∞–π–ª—ã –ø–æ—è–≤—è—Ç—Å—è –≤ `/tmp/investing_calendar_USA.html` –∏ —Ç.–¥.

4. **–ü–æ –æ–¥–Ω–æ–º—É –∏—Å—Ç–æ—á–Ω–∏–∫—É —á–µ—Ä–µ–∑ –æ–±—â–∏–π —Å–∫—Ä–∏–ø—Ç:**
   ```bash
   ./test_all_news_sources.sh
   ```
   –ü–æ –æ—á–µ—Ä–µ–¥–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç RSS, Investing.com, NewsAPI, Alpha Vantage.

5. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞:**
   ```bash
   # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ knowledge_base (–Ω–æ–≤–æ—Å—Ç–∏, earnings, —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã)
   psql $DATABASE_URL -c "SELECT ts, ticker, source, event_type, LEFT(content, 60) FROM knowledge_base ORDER BY ts DESC LIMIT 15;"
   
   # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ quotes (RSI, MACD –∏ —Ç.–¥.)
   psql $DATABASE_URL -c "SELECT date, ticker, rsi, macd, adx FROM quotes WHERE rsi IS NOT NULL ORDER BY date DESC LIMIT 10;"
   ```
   (–ü–æ–¥—Å—Ç–∞–≤—å—Ç–µ —Å–≤–æ—é `DATABASE_URL` –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏–∑ `config.env`.)

---

**–°—Ç–∞—Ç—É—Å:** –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ; cron –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ `./setup_cron.sh`  
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2026-02-19
